{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cleaning each data  ame before merging\n",
    "we will keep the attribute 'fuente' to created the computed\n",
    "tables with it but well make sure to erase it after merging and computation'''\n",
    "df_museos = pd.read_csv('museos/2022-07/26-07-2022.csv')\n",
    "## Deleting the columns we dont need\n",
    "df_museos.drop(df_museos.columns[[3,4,10,12,16,17,18,19,21,22,23]], axis=1, inplace=True)\n",
    "## renaming the columns\n",
    "new_name = ['cod_localidad',\n",
    "            'id_provincia',\n",
    "            'id_departamento',\n",
    "            'categoria',\n",
    "            'provincia',\n",
    "            'localidad',\n",
    "            'nombre',\n",
    "            'domicilio',\n",
    "            'codigo_postal',\n",
    "            'numero_telefono',\n",
    "            'mail',\n",
    "            'web',\n",
    "            'fuente']\n",
    "df_museos.columns = new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning cines dataset\n",
    "df_cines = pd.read_csv('cines/2022-07/26-07-2022.csv')\n",
    "### Deleting the columns we dont need\n",
    "df_cines.drop(df_cines.columns[[3,6,10,12,16,17,18,19,21,22,23,24,25]], axis=1, inplace=True)\n",
    "### renaming the columns\n",
    "df_cines.columns = new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning bibliotecas dataset \n",
    "df_bib = pd.read_csv('bibliotecas/2022-07/26-07-2022.csv')\n",
    "df_bib.drop(df_bib.columns[[3,5,7,11,13,17,18,19,20,22,23,24]], axis=1, inplace=True)\n",
    "## rename the columns\n",
    "df_bib.columns = new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Concadenating the cleaned dataframes\n",
    "df_combi = pd.concat([df_museos, df_cines, df_bib])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating 3 new tables with computated information. The challenge info\n",
    "### said it was one table but it makes more sense like this in my humble opinion\n",
    "df_cat_total = df_combi.groupby('categoria', as_index=False)['cod_localidad'].count()\n",
    "df_cat_total.columns = ['categoria', 'total']\n",
    "df_fuente_total = df_combi.groupby('fuente', as_index=False )['cod_localidad'].count()\n",
    "df_fuente_total.columns = ['fuente', 'total']\n",
    "df_prov_cat_total = df_combi.groupby(['provincia', 'categoria'], as_index=False)['cod_localidad'].count()\n",
    "df_prov_cat_total.columns = ['provincia', 'categoria', 'total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Erasing the attirubute 'fuente' because it is not needed for the tables anymore\n",
    "df_combi.drop(['fuente'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Datos con lo de los cines.\n",
    "df_cines2 = pd.read_csv('cines/2022-07/26-07-2022.csv')\n",
    "df_comp = df_cines2.groupby('Provincia', as_index=False)['Pantallas','Butacas', 'espacio_INCAA'].sum()\n",
    "df_comp['espacio_INCAA'] = df_cines2.groupby('Provincia', as_index=False)['espacio_INCAA'].count()['espacio_INCAA']\n",
    "### rename columns to fit sql table\n",
    "df_comp.columns = ['provincia', 'num_pantallas', 'num_butacas', 'num_incaa']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now we will export the dataframe info to the sql server in docker.\n",
    "'''\n",
    "## Creating the connection to the server\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://docker:docker@localhost:5432/challenge_db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_prov_cat_total.to_sql('categoria_provincia_total', engine, if_exists='append', index=False)\n",
    "df_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add a time stamp to all the dataframes\n",
    "### Table - Datafram pairing\n",
    "df_pairings = {\n",
    "    #table name: dataframe\n",
    "    'registros_combi': df_combi,\n",
    "    'cines': df_comp,\n",
    "    'categoria_total': df_cat_total,\n",
    "    'fuentes_total': df_fuente_total,\n",
    "    'categoria_provincia_total': df_prov_cat_total\n",
    "}\n",
    "for value in df_pairings.values():\n",
    "    value['fecha_subida'] = dt.now().strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## populating the tablereplaces\n",
    "for table, dataf in df_pairings.items():\n",
    "    dataf.to_sql(table, engine, if_exists='append', index=False)\n",
    "    print(f'{table} populated')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95c7506c8f8d91b5a85a354a8d0eccc2efc54cbb7157a8737604e7d7e34f8141"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
